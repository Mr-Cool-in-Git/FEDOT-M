{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm1av9t8SRpe"
      },
      "outputs": [],
      "source": [
        "!pip install fedot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6jxJJkeaSUHw"
      },
      "outputs": [],
      "source": [
        "import fedot\n",
        "from fedot.api.main import Fedot\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "SEED = 2022\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "data_path = '/content/drive/MyDrive/Datasets/diploma/datasets/'\n",
        "for dirpath, dirnames, filenames in os.walk(data_path):\n",
        "    path = dirpath\n",
        "    filelist = filenames"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(filelist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8etLIIdzcdNq",
        "outputId": "299204f6-700a-4e04-faae-3d54631c63bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv('/content/fedot_metabase_3_0-14.csv')\n",
        "data2 = pd.read_csv('/content/fedot_metabase_3_15-28.csv')\n",
        "data3 = pd.read_csv('/content/fedot_metabase_3_29-46.csv')\n",
        "data4 = pd.read_csv('/content/fedot_metabase_3_46-64.csv')\n",
        "\n",
        "full = pd.concat([data1,data2, data3, data4],0,ignore_index=True)\n",
        "# full = full[full['0']>0.6]\n",
        "\n",
        "# full.to_csv('meta_base_v1.csv', index=False)"
      ],
      "metadata": {
        "id": "lArA8ehPXy4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J9c08Xlz6z-L"
      },
      "outputs": [],
      "source": [
        "score_list = [[],[]]\n",
        "for i, filename in zip(range(55,65), filelist):\n",
        "  if i in [44,51,52,58]:\n",
        "    continue\n",
        "  clear_output(wait=True)\n",
        "  print(str(i)+'/'+str(len(filelist)))\n",
        "\n",
        "  data = pd.read_csv(os.path.join(data_path, filelist[i]))\n",
        "  if data.columns[0] == 'Unnamed: 0':\n",
        "      data = pd.read_csv(os.path.join(data_path, filelist[i]), index_col=0)\n",
        "  \n",
        "  try:\n",
        "    X, y = data.drop(['target'], axis=1), data['target']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=SEED)\n",
        "\n",
        "    model = Fedot(problem='classification',seed=SEED,composer_params={\n",
        "            'max_depth': 5,\n",
        "            'max_arity': 5,\n",
        "            'pop_size': 20,\n",
        "            'num_of_generations': 20,\n",
        "            'timeout': 3,\n",
        "            'with_tuning': True,\n",
        "            'preset': 'best_quality',\n",
        "            'genetic_scheme': None,\n",
        "            'history_folder': None,\n",
        "            'stopping_after_n_generation': 10,\n",
        "            'cv_folds': 3,\n",
        "            'problem': 'classification',\n",
        "            'available_operations': ['bernb', 'catboost', 'dt', 'knn', 'lda', 'lgbm', 'logit', 'mlp', 'qda', 'rf',\n",
        "                                  'xgboost', 'scaling', 'normalization', 'simple_imputation', 'pca', 'kernel_pca',\n",
        "                                  'poly_features', 'one_hot_encoding', 'rfe_lin_class', 'rfe_non_lin_class',\n",
        "                                  'resample']})\n",
        "    model.fit(features=X_train.values, target=y_train.values)\n",
        "    prediction = model.predict(features=X_test.values)\n",
        "\n",
        "    score_list[0].append(f1_score(y_test, prediction, average='weighted'))\n",
        "    score_list[1].append(str(model.best_models[0]))\n",
        "  except:\n",
        "    score_list[0].append(0)\n",
        "    score_list[1].append('None')\n",
        "  clear_output(wait=False)\n",
        "  score_df = pd.DataFrame(score_list).T.to_csv(\"fedot_metabase_3_55-\"+str(i)+\".csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oVR2KME1PUh"
      },
      "outputs": [],
      "source": [
        "# score_df = pd.DataFrame(score_list).T\n",
        "# score_df.to_csv(\"fedot_metabase_1_40-60.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoZ7gZ1EB8b8"
      },
      "outputs": [],
      "source": [
        "# data1 = pd.read_csv('/content/fedot_metabase_2_0-15.csv')\n",
        "# data2 = pd.read_csv('/content/fedot_metabase_2_20-40.csv')\n",
        "# data3 = pd.read_csv('/content/fedot_metabase_2_40-60.csv')\n",
        "# data = pd.concat([data1,data2,data3], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFKLD2RGoK8S"
      },
      "outputs": [],
      "source": [
        "name_df = []\n",
        "idx = []\n",
        "for i in range(len(filelist)):\n",
        "  if i in [19,44,58]:\n",
        "    continue\n",
        "  if i == 60:\n",
        "    break\n",
        "  name_df.append(filelist[i])\n",
        "  idx.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqOf70PEoK5d"
      },
      "outputs": [],
      "source": [
        "data['dataset_name'] = name_df\n",
        "data['idx'] = idx\n",
        "\n",
        "metabase = data[data['0']>0.8]\n",
        "metabase = metabase.drop([17,30],0)\n",
        "metabase.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8B5zlPEonkO"
      },
      "outputs": [],
      "source": [
        "name_list = []\n",
        "for i, filename in zip(range(0,65), filelist):\n",
        "  if i in [44,51,52,58]:\n",
        "    continue\n",
        "  name_list.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full = full.drop(46)"
      ],
      "metadata": {
        "id": "rdbk0FuZaH_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(name_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhiM01LVZnqi",
        "outputId": "d5ec6bbf-e122-4f89-ebf2-eeccec08c42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full['ds_name'] = name_list"
      ],
      "metadata": {
        "id": "cg80cUerZ3X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full.to_csv('meta_base_v1.csv', index=False)"
      ],
      "metadata": {
        "id": "1mUW3dRvaTnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-1sr1Yyo1ih"
      },
      "source": [
        "## Generation meta-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y15N1m3o5Ex"
      },
      "outputs": [],
      "source": [
        "!pip install pymfe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNNnM3rroKvx"
      },
      "outputs": [],
      "source": [
        "import pymfe\n",
        "from pymfe.mfe import MFE\n",
        "from pymfe.concept import MFEConcept\n",
        "from pymfe.complexity import MFEComplexity\n",
        "from pymfe.general import MFEGeneral\n",
        "from pymfe.statistical import MFEStatistical\n",
        "from pymfe.landmarking import MFELandmarking\n",
        "from pymfe.model_based import MFEModelBased\n",
        "from pymfe.info_theory import MFEInfoTheory\n",
        "from pymfe.clustering import MFEClustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full = pd.read_csv('/content/meta_base_v1.csv')"
      ],
      "metadata": {
        "id": "1D4aqCyKsQll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMOSwB2ypqDA"
      },
      "outputs": [],
      "source": [
        "metafeatures = np.empty((24,61))\n",
        "for g in range(58,61):\n",
        "  print(g)\n",
        "  # if g in [44,48,52,58]:\n",
        "  #   pd.DataFrame(metafeatures.T).to_csv('mf-58-'+str(g)+'.csv', index=False)\n",
        "  #   continue\n",
        "  temp_df = pd.read_csv(os.path.join(data_path, filelist[g]))\n",
        "  if temp_df.columns[0] == 'Unnamed: 0':\n",
        "      temp_df = pd.read_csv(os.path.join(data_path, filelist[g]), index_col=0)\n",
        "  X, y = temp_df.drop(['target'],1).values, temp_df.target\n",
        "\n",
        "  i = g\n",
        "  try:\n",
        "    metafeatures[0,i] = np.std(MFEConcept.ft_conceptvar(X,y),ddof=1)\n",
        "    metafeatures[1,i] = MFEComplexity.ft_lsc(X,y)\n",
        "    metafeatures[2,i] = np.std(MFEGeneral.ft_freq_class(X,y),ddof=1)\n",
        "    metafeatures[3,i] = np.mean(MFEComplexity.ft_n3(X,y.values))\n",
        "    metafeatures[4,i] = MFEStatistical.ft_nr_cor_attr(X)\n",
        "    metafeatures[5,i] = np.mean(MFEComplexity.ft_f1(X,y))\n",
        "    metafeatures[6,i] = MFEComplexity.ft_c2(X,y)\n",
        "    metafeatures[7,i] = np.mean(MFEComplexity.ft_f4(X,y))\n",
        "    metafeatures[8,i] = MFEComplexity.ft_n1(X,y.values)\n",
        "    metafeatures[9,i] = np.mean(MFEComplexity.ft_l1(X,y))\n",
        "    metafeatures[10,i] = np.mean(MFELandmarking.ft_best_node(X,y,score=pymfe.scoring.accuracy))\n",
        "    metafeatures[11,i] = np.mean(MFELandmarking.ft_linear_discr(X,y,score=pymfe.scoring.accuracy))\n",
        "    metafeatures[12,i] = MFE(groups=[\"model-based\"]).fit(X,y.values).extract()[1][7]\n",
        "    metafeatures[13,i] = MFEGeneral.ft_nr_class(X,y)\n",
        "    metafeatures[14,i] = np.mean(MFEGeneral.ft_freq_class(X,y))\n",
        "    metafeatures[15,i] = np.mean(MFELandmarking.ft_elite_nn(X,y,score=pymfe.scoring.accuracy))\n",
        "    metafeatures[16,i] = np.mean(MFEConcept.ft_conceptvar(X,y))\n",
        "    metafeatures[17,i] = np.mean(MFEComplexity.ft_l2(X,y))\n",
        "    metafeatures[18,i] = np.mean(MFEComplexity.ft_f1v(X,y))\n",
        "    metafeatures[19,i] = MFEClustering.ft_nre(X,y)\n",
        "    metafeatures[20,i] = np.mean(MFELandmarking.ft_random_node(X,y,score=pymfe.scoring.accuracy))\n",
        "    metafeatures[21,i] = np.mean(MFELandmarking.ft_worst_node(X,y,score=pymfe.scoring.accuracy))\n",
        "    metafeatures[22,i] = np.mean(MFEComplexity.ft_l3(X,y))\n",
        "    metafeatures[23,i] = np.mean(np.log1p(MFEInfoTheory.ft_class_ent(X,y)))\n",
        "  except:\n",
        "    pass\n",
        "  pd.DataFrame(metafeatures.T).to_csv('mf-58-'+str(i)+'.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full.drop([19,29,44,48,52,58]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePx2p3ueHQ0X",
        "outputId": "515b4004-4456-4f68-fa33-2cbe1de5a62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-9q6_c7DaNs"
      },
      "outputs": [],
      "source": [
        "metafeats = pd.concat([pd.read_csv('/content/mf-0-14.csv')[:14],pd.read_csv('/content/mf-15-18.csv')[15:18],pd.read_csv('/content/mf-19-28.csv')[19:28],\\\n",
        "                       pd.read_csv('/content/mf-29-43.csv')[29:43],pd.read_csv('/content/mf-44-51.csv')[44:51],pd.read_csv('/content/mf-52-57.csv')[52:57],pd.read_csv('/content/mf-58-60.csv')[58:60]], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB0neDATH1dB"
      },
      "outputs": [],
      "source": [
        "metafeats.columns = ['conceptvar_sd','lsc','freq_class_sd','n3_mean','nr_cor_attr','f1_mean','c2','f4_mean','n1','l1_mean',\n",
        "                                    'best_node_mean','linear_discr_mean','leaves_per_class_mean','nr_class','freq_class_mean','elite_nn_mean','conceptvar_mean',\n",
        "                                    'l2_mean','f1v_mean','nre','random_node_mean','worst_node_mean','l3_mean','class_ent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNVVHdsXpqFT"
      },
      "outputs": [],
      "source": [
        "metabase = pd.concat([full.drop([19,29,44,48,52,58]).reset_index(drop=True), metafeats.reset_index(drop=True)],1).drop([47,44,40,26,17,54])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7vkNJnmoKHs"
      },
      "outputs": [],
      "source": [
        "#metabase.to_csv('/content/meta_base_v1.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MuuBVsRpky_"
      },
      "source": [
        "## Эксперименты"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metabase = pd.read_csv('/content/meta_base_v1.csv')"
      ],
      "metadata": {
        "id": "e00rGFWIKIyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auPyFLAfInzO"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAGQOdamIGx7"
      },
      "outputs": [],
      "source": [
        "def parse_configs(configs):\n",
        "  params = dict()\n",
        "  params['max_depth'] = int(re.findall('[0-9]',configs)[0])\n",
        "  params['max_arity'] = int(re.findall('[0-9]',configs)[0])\n",
        "  params['available_operations'] = re.sub('[\\,\\[\\]]','',re.findall('\\[.{0,}\\]',configs)[0]).split(' ')\n",
        "  return params\n",
        "#parse_configs(metabase['1'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1aFzeDfMxvD"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metabase['idx'] = metabase.index"
      ],
      "metadata": {
        "id": "Vy2svISHEMI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EENr0k2TLwcu",
        "outputId": "62508d1d-13d5-456d-c8e7-9bb10ff224f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
              "       36, 37, 38, 39, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#обучение леса\n",
        "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "knn.fit(metabase.iloc[:,3:-1].fillna(0), metabase.iloc[:,-1])\n",
        "knn.predict(metabase.iloc[:,3:-1].fillna(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chbpWA2cIHer"
      },
      "outputs": [],
      "source": [
        "# with open('metasearcher.pickle', 'wb') as f:\n",
        "#   pickle.dump(knn, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQIMqzW8QQma"
      },
      "outputs": [],
      "source": [
        "def get_metafeats(df):\n",
        "  metafeatures = np.empty((24,1))\n",
        "  X, y = df.drop(['target'],1).values, df.target\n",
        "\n",
        "  metafeatures[0,0] = np.std(MFEConcept.ft_conceptvar(X,y),ddof=1)\n",
        "  metafeatures[1,0] = MFEComplexity.ft_lsc(X,y)\n",
        "  metafeatures[2,0] = np.std(MFEGeneral.ft_freq_class(X,y),ddof=1)\n",
        "  metafeatures[3,0] = np.mean(MFEComplexity.ft_n3(X,y.values))\n",
        "  metafeatures[4,0] = MFEStatistical.ft_nr_cor_attr(X)\n",
        "  metafeatures[5,0] = np.mean(MFEComplexity.ft_f1(X,y))\n",
        "  metafeatures[6,0] = MFEComplexity.ft_c2(X,y)\n",
        "  metafeatures[7,0] = np.mean(MFEComplexity.ft_f4(X,y))\n",
        "  metafeatures[8,0] = MFEComplexity.ft_n1(X,y.values)\n",
        "  metafeatures[9,0] = np.mean(MFEComplexity.ft_l1(X,y))\n",
        "  metafeatures[10,0] = np.mean(MFELandmarking.ft_best_node(X,y,score=pymfe.scoring.accuracy))\n",
        "  metafeatures[11,0] = np.mean(MFELandmarking.ft_linear_discr(X,y,score=pymfe.scoring.accuracy))\n",
        "  metafeatures[12,0] = MFE(groups=[\"model-based\"]).fit(X,y.values).extract()[1][7]\n",
        "  metafeatures[13,0] = MFEGeneral.ft_nr_class(X,y)\n",
        "  metafeatures[14,0] = np.mean(MFEGeneral.ft_freq_class(X,y))\n",
        "  metafeatures[15,0] = np.mean(MFELandmarking.ft_elite_nn(X,y,score=pymfe.scoring.accuracy))\n",
        "  metafeatures[16,0] = np.mean(MFEConcept.ft_conceptvar(X,y))\n",
        "  metafeatures[17,0] = np.mean(MFEComplexity.ft_l2(X,y))\n",
        "  metafeatures[18,0] = np.mean(MFEComplexity.ft_f1v(X,y))\n",
        "  metafeatures[19,0] = MFEClustering.ft_nre(X,y)\n",
        "  metafeatures[20,0] = np.mean(MFELandmarking.ft_random_node(X,y,score=pymfe.scoring.accuracy))\n",
        "  metafeatures[21,0] = np.mean(MFELandmarking.ft_worst_node(X,y,score=pymfe.scoring.accuracy))\n",
        "  metafeatures[22,0] = np.mean(MFEComplexity.ft_l3(X,y))\n",
        "  metafeatures[23,0] = np.mean(np.log1p(MFEInfoTheory.ft_class_ent(X,y)))\n",
        "  return metafeatures.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVdcd-wgYnkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844c57fb-16a4-431f-bea4-e26735dde1d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generations:   5%|▌         | 1/20 [01:20<?, ?gen/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters optimization start\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0%|          | 4/1000 [11:21<47:09:19, 170.44s/trial, best loss: -0.9108903620329387]\n",
            "Hyperparameters optimization finished\n",
            "Return tuned pipeline due to the fact that obtained metric 0.911 equal or bigger than initial (- 5% deviation) 0.885\n"
          ]
        }
      ],
      "source": [
        "results1 = [[],[],[]]\n",
        "for i in range(108,115):\n",
        "  # if i in [73, 109]:\n",
        "  #   continue\n",
        "  clear_output(wait=False)\n",
        "  print(i)\n",
        "  temp_df = pd.read_csv(os.path.join(data_path, filelist[i]))\n",
        "  if temp_df.columns[0] == 'Unnamed: 0':\n",
        "      temp_df = pd.read_csv(os.path.join(data_path, filelist[i]), index_col=0)\n",
        "\n",
        "  X, y = temp_df.drop(['target'], axis=1), temp_df['target']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=SEED)\n",
        "\n",
        "  model = Fedot(problem='classification',seed=47,\n",
        "      composer_params={'timeout':3})\n",
        "  start = time.time()\n",
        "  model.fit(features=X_train.values, target=y_train.values)\n",
        "  results1[0].append(filelist[i])\n",
        "  results1[1].append(time.time()-start)\n",
        "\n",
        "  prediction = model.predict(features=X_test.values)\n",
        "  results1[2].append(f1_score(y_test, prediction, average='weighted'))\n",
        "  pd.DataFrame(results1).to_csv('default_fedot-108'+str(i)+'.csv',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHzbeMfPPLhJ"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(results1).to_csv('notmy.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AWnNhS4wPVh"
      },
      "outputs": [],
      "source": [
        "#metabase = metabase.set_index('idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWHhVNhXSUcT",
        "outputId": "430b5e41-c823-4884-de28-284d1ab33b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generations:  10%|█         | 2/20 [01:11<21:20, 71.12s/gen]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters optimization start\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 21%|██▏       | 213/1000 [03:00<11:05,  1.18trial/s, best loss: -0.9321730654970525]\n",
            "Hyperparameters optimization finished\n",
            "Return tuned pipeline due to the fact that obtained metric 0.932 equal or bigger than initial (- 5% deviation) 0.879\n"
          ]
        }
      ],
      "source": [
        "results = [[],[],[]]\n",
        "for i in range(108, 115):\n",
        "  # if i in [51,52, 73, 75,80,82,83,91, 94,99,100,102,108,109]:\n",
        "  #   continue\n",
        "  clear_output(wait=False)\n",
        "  print(i)\n",
        "  temp_df = pd.read_csv(os.path.join(data_path, filelist[i]))\n",
        "  if temp_df.columns[0] == 'Unnamed: 0':\n",
        "      temp_df = pd.read_csv(os.path.join(data_path, filelist[i]), index_col=0)\n",
        "\n",
        "  #try:\n",
        "  temp_df_metafeats = get_metafeats(temp_df)\n",
        "  temp_meta_idx = knn.predict(pd.DataFrame(temp_df_metafeats).fillna(0).replace(-np.inf,0).replace(np.inf,0))[0]\n",
        "  temp_params = parse_configs(metabase.loc[temp_meta_idx,'1'])\n",
        "  temp_params['timeout'] = 3\n",
        "\n",
        "  X, y = temp_df.drop(['target'], axis=1), temp_df['target']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=SEED)\n",
        "\n",
        "  model = Fedot(problem='classification',seed=47,\n",
        "      composer_params=temp_params)\n",
        "  start = time.time()\n",
        "  model.fit(features=X_train.values, target=y_train.values)\n",
        "  results[0].append(filelist[i])\n",
        "  results[1].append(time.time()-start)\n",
        "\n",
        "  prediction = model.predict(features=X_test.values)\n",
        "  results[2].append(f1_score(y_test, prediction, average='weighted'))\n",
        "  # except:\n",
        "  #   results[0].append(filelist[i])\n",
        "  #   results[1].append(0)\n",
        "  #   results[2].append(0)\n",
        "  pd.DataFrame(results).to_csv('my_fedot-108'+str(i)+'.csv',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DjOcX-ZzNQo"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(results).to_csv('my.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47IGeO31pI0-"
      },
      "outputs": [],
      "source": [
        "const_composer_params = ['scaling', 'normalization', 'simple_imputation', 'pca', 'kernel_pca',\n",
        "                                  'poly_features', 'one_hot_encoding',\n",
        "                                  'resample']\n",
        "nonconst_composer_params = ['bernb', 'catboost', 'dt','knn', 'lda', 'lgbm', 'logit', 'mlp', 'qda', 'rf','rfe_lin_class', 'rfe_non_lin_class']\n",
        "sctructure_meta_base = ['dataset_name', 'score:_', 'conf','mf:_']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FcDsTbxpI63"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "experiment.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}